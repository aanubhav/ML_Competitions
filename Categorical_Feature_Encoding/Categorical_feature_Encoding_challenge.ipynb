{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics, preprocessing\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    def fallback_auc(y_true, y_pred):\n",
    "        try:\n",
    "            return metrics.roc_auc_score(y_true, y_pred)\n",
    "        except:\n",
    "            return 0.5\n",
    "    return tf.py_function(fallback_auc, (y_true, y_pred), tf.double)\n",
    "#     return metrics.roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(data, catcols):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for c in catcols:\n",
    "        num_unique_values = int(data[c].nunique())\n",
    "        embed_dim = int(min(np.ceil((num_unique_values)/2), 50))\n",
    "        inp = layers.Input(shape=(1,))\n",
    "        out = layers.Embedding(num_unique_values+1, embed_dim, name=c)(inp)\n",
    "        out = layers.SpatialDropout1D(0.3)(out)\n",
    "        out = layers.Reshape(target_shape=(embed_dim, ))(out)\n",
    "        inputs.append(inp)\n",
    "        outputs.append(out)\n",
    "        \n",
    "    x = layers.Concatenate()(outputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Dense(300, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Dense(300, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    y = layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=y)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment\n",
    "model = create_model(data, features)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../Data/Cat-in-the-dat/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f'{data_dir}train.csv')\n",
    "test = pd.read_csv(f'{data_dir}test.csv')\n",
    "sample = pd.read_csv(f'{data_dir}sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Bit of EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['day'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample) == len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test['target'] = -1\n",
    "data = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features = [x for x in train.columns if x not in ['id', 'target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for feat in features:\n",
    "    label_enc = preprocessing.LabelEncoder()\n",
    "    data[feat] = label_enc.fit_transform(data[feat].fillna('-1').\n",
    "                                         astype(str).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data.nom_6.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['target'] = -1\n",
    "data = pd.concat([train, test]).reset_index(drop=True)\n",
    "\n",
    "features = [x for x in train.columns if x not in ['id', 'target']]\n",
    "\n",
    "for feat in features:\n",
    "    label_enc = preprocessing.LabelEncoder()\n",
    "    data[feat] = label_enc.fit_transform(data[feat].fillna('-1').\n",
    "                                         astype(str).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train), len(test), len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data.target != -1].reset_index(drop=True)\n",
    "test = data[data.target == -1].reset_index(drop=True)\n",
    "\n",
    "test_data = [test.loc[:, features].values[:, k] for k in \n",
    "             range(test.loc[:, features].values.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.loc[:, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((test.loc[:, features]).values[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test.loc[:, features].values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train.target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds = np.zeros(len(train))\n",
    "test_preds = np.zeros(len(test))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=50)\n",
    "\n",
    "for train_index, test_index in skf.split(train, train.target.values):\n",
    "    X_train, X_test = train.iloc[train_index, :], train.iloc[test_index, :]\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    y_train, y_test = X_train.target.values, X_test.target.values\n",
    "    \n",
    "    model = create_model(data, features)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "                  metrics = [auc])\n",
    "    \n",
    "    X_train = [X_train.loc[:, features].values[:, k] for k in range(X_train.loc[:, features].values.shape[1])]\n",
    "    \n",
    "    X_test = [X_test.loc[:, features].values[:, k] for k in range(X_test.loc[:, features].values.shape[1])]\n",
    "    \n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor='val_auc', min_delta=0.001,\n",
    "                                 patience=5, verbose=1, mode='max',\n",
    "                                baseline=None, restore_best_weights=True)\n",
    "    rlr = callbacks.ReduceLROnPlateau(monitor='val_auc', factor=0.5,\n",
    "                                    patience=3, min_lr=1e-06, mode='max',\n",
    "                                    verbose=1)\n",
    "    \n",
    "    model.fit(X_train, utils.to_categorical(y_train), \n",
    "             validation_data=(X_test, utils.to_categorical(y_test)),\n",
    "             verbose=1, batch_size=1024, callbacks=[es, rlr],\n",
    "             epochs = 100)\n",
    "    \n",
    "    vaild_fold_preds = model.predict(X_test)[:, 1]\n",
    "    test_fold_preds = model.predict(test_data)[:, 1]\n",
    "    \n",
    "    oof_preds[test_index] = valid_fold_preds.ravel()\n",
    "    \n",
    "    test_preds += test_fold_preds.ravel()\n",
    "    \n",
    "    print(metrics.roc_auc_score(y_test, valid_fold_preds))\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Overall AUC = {}'.format(metrics.roc_auc_score(train.target.values,\n",
    "                                                     oof_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds /= 50\n",
    "test_ids = test.id.values\n",
    "print(\"saving submisssion file\")\n",
    "\n",
    "submission = pd.DataFrame.from_dict({'id': test_ids,\n",
    "                                    'target': test_preds})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
